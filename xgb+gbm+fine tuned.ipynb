{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier, StackingClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Step 1: Load the data\n",
        "data = pd.read_csv('ac.csv')\n",
        "\n",
        "# Step 2: Separate features and labels\n",
        "X = data.iloc[:, :-1]  # Features (all columns except the last one)\n",
        "y = data.iloc[:, -1]   # Labels (the last column)\n",
        "\n",
        "# Adjust labels to start from 0, if necessary\n",
        "y = y - 1\n",
        "\n",
        "# Step 3: Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 4: Define the base classifiers\n",
        "xgb_clf = XGBClassifier(objective='binary:logistic', use_label_encoder=False, eval_metric='logloss')\n",
        "gbm_clf = GradientBoostingClassifier(random_state=42)\n",
        "\n",
        "# Step 5: Define the parameter grids for each classifier\n",
        "xgb_param_grid = {\n",
        "    'xgb__max_depth': [3, 4, 5],\n",
        "    'xgb__alpha': [1, 10],\n",
        "    'xgb__learning_rate': [0.01, 0.1, 1.0],\n",
        "    'xgb__n_estimators': [100, 200]\n",
        "}\n",
        "\n",
        "gbm_param_grid = {\n",
        "    'gbm__n_estimators': [100, 200],\n",
        "    'gbm__max_depth': [3, 4, 5],\n",
        "    'gbm__learning_rate': [0.01, 0.1, 1.0]\n",
        "}\n",
        "\n",
        "# Step 6: Define the stacking classifier\n",
        "stacking_clf = StackingClassifier(\n",
        "    estimators=[\n",
        "        ('xgb', xgb_clf),\n",
        "        ('gbm', gbm_clf)\n",
        "    ],\n",
        "    final_estimator=XGBClassifier(objective='binary:logistic', use_label_encoder=False, eval_metric='logloss'),\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Step 7: Perform GridSearchCV to find the best hyperparameters for the stacking classifier\n",
        "param_grid = {**xgb_param_grid, **gbm_param_grid}\n",
        "grid_search = GridSearchCV(stacking_clf, param_grid, cv=5, scoring='accuracy', verbose=1, n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Step 8: Evaluate the best estimator found by GridSearchCV\n",
        "best_clf = grid_search.best_estimator_\n",
        "\n",
        "# Perform cross-validation on the training set\n",
        "cv_scores = cross_val_score(best_clf, X_train, y_train, cv=5, scoring='accuracy')\n",
        "\n",
        "# Print cross-validation scores\n",
        "print(f'Cross-validation scores: {cv_scores}')\n",
        "print(f'Mean cross-validation score: {cv_scores.mean():.2f}')\n",
        "\n",
        "# Step 9: Evaluate the classifier on the test set\n",
        "y_pred = best_clf.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy on test set: {accuracy:.2f}')\n",
        "\n",
        "# Print detailed classification report\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Print the best parameters found by GridSearchCV\n",
        "print(f'Best parameters: {grid_search.best_params_}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3s-1ZwzlCSvt",
        "outputId": "becb0f8c-f141-4bd9-937d-69e697db9ad3"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 648 candidates, totalling 3240 fits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bbwf1TuCDjhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RBG2ixzxQXzk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}